# question_generator.py
# â˜…â˜…â˜… ä¿®æ­£ç‰ˆ - ä½¿ç”¨ httpx åŒæ­¥æ¨¡å¼åœ¨ executor ä¸­åŸ·è¡Œ â˜…â˜…â˜…

import os
import json
import httpx
import asyncio
from concurrent.futures import ThreadPoolExecutor
from dotenv import load_dotenv
import traceback

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

DEFAULT_QUESTIONS = [
    "è«‹ç°¡å–®è‡ªæˆ‘ä»‹ç´¹ï¼Œä¸¦èªªæ˜ä½ ç‚ºä»€éº¼å°é€™å€‹é ˜åŸŸæœ‰èˆˆè¶£ï¼Ÿ",
    "ä½ èªç‚ºè‡ªå·±æœ€å¤§çš„å„ªé»å’Œéœ€è¦æ”¹é€²çš„åœ°æ–¹æ˜¯ä»€éº¼ï¼Ÿ",
    "è«‹åˆ†äº«ä¸€å€‹ä½ å…‹æœå›°é›£çš„ç¶“é©—ï¼Œä½ å¾ä¸­å­¸åˆ°äº†ä»€éº¼ï¼Ÿ",
    "è«‡è«‡ä½ å°æœªä¾†çš„è¦åŠƒï¼Œä»¥åŠé€™å€‹ç›®æ¨™å°ä½ çš„æ„ç¾©ã€‚",
    "å¦‚æœéŒ„å–å¾Œï¼Œä½ å¸Œæœ›åœ¨é€™è£¡å­¸åˆ°ä»€éº¼ï¼Ÿ"
]

# â˜…â˜…â˜… å»ºç«‹å…±ç”¨çš„ ThreadPoolExecutor â˜…â˜…â˜…
executor = ThreadPoolExecutor(max_workers=4)


def _process_pdf_and_call_openai_sync(pdf_path: str, interview_type: str) -> dict:
    """
    åŒæ­¥è™•ç† PDF ä¸¦å‘¼å« OpenAI (åœ¨ç¨ç«‹ç·šç¨‹ä¸­åŸ·è¡Œ)
    é€™æ¨£å³ä½¿å‡ºéŒ¯ä¹Ÿä¸æœƒå½±éŸ¿ä¸»ç¨‹å¼
    """
    try:
        print(f"ğŸ” [Worker] é–‹å§‹è™•ç†: {pdf_path}")
        print(f"ğŸ“Œ é¡å‹: {interview_type}")
        
        if not os.path.exists(pdf_path):
            print("âŒ æª”æ¡ˆä¸å­˜åœ¨")
            return {"success": True, "questions": DEFAULT_QUESTIONS}
        
        # è®€å– PDF
        print("ğŸ“„ è®€å– PDF...")
        try:
            from PyPDF2 import PdfReader
            reader = PdfReader(pdf_path)
            text = ""
            for page in reader.pages:
                t = page.extract_text()
                if t:
                    text += t + "\n"
            print(f"ğŸ“„ æå– {len(text)} å­—")
        except Exception as e:
            print(f"âš ï¸ PDF è®€å–å¤±æ•—: {e}")
            traceback.print_exc()
            return {"success": True, "questions": DEFAULT_QUESTIONS}
        
        if not text.strip():
            print("âš ï¸ PDF ç„¡æ–‡å­—")
            return {"success": True, "questions": DEFAULT_QUESTIONS}
        
        # æª¢æŸ¥ API Key
        if not OPENAI_API_KEY or len(OPENAI_API_KEY) < 10:
            print("âš ï¸ ç„¡ API Key")
            return {"success": True, "questions": DEFAULT_QUESTIONS}
        
        # é™åˆ¶é•·åº¦
        if len(text) > 5000:
            text = text[:5000]
        
        # â˜…â˜…â˜… ä½¿ç”¨ httpx åŒæ­¥æ¨¡å¼å‘¼å« OpenAI â˜…â˜…â˜…
        print("ğŸ¤– å‘¼å« OpenAI (åŒæ­¥ï¼Œåœ¨ç¨ç«‹ç·šç¨‹ä¸­)...")
        
        prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„å¤§å­¸é¢è©¦å®˜ã€‚è«‹æ ¹æ“šä»¥ä¸‹å­¸ç”Ÿçš„å­¸ç¿’æ­·ç¨‹å…§å®¹ï¼Œç”Ÿæˆ 5 å€‹é‡å°é€™ä½å­¸ç”Ÿå…·é«”ç¶“æ­·çš„å€‹äººåŒ–é¢è©¦å•é¡Œã€‚

ã€é¢è©¦é¡å‹ã€‘{interview_type}

ã€å­¸ç¿’æ­·ç¨‹å…§å®¹ã€‘
{text}

ã€è¦æ±‚ã€‘
1. å•é¡Œå¿…é ˆé‡å°å­¸ç”Ÿæåˆ°çš„å…·é«”ç¶“é©—ã€å°ˆæ¡ˆã€æ´»å‹•ä¾†æå•
2. ä¸è¦å•æ³›æ³›çš„å•é¡Œ
3. ç”¨ç¹é«”ä¸­æ–‡

ã€è¼¸å‡ºæ ¼å¼ã€‘
åªå›å‚³ JSON é™£åˆ—ï¼š["å•é¡Œ1", "å•é¡Œ2", "å•é¡Œ3", "å•é¡Œ4", "å•é¡Œ5"]"""
        
        # ä½¿ç”¨åŒæ­¥ httpxï¼ˆåœ¨ç·šç¨‹ä¸­åŸ·è¡Œæ‰€ä»¥ä¸æœƒé˜»å¡ä¸»ç¨‹å¼ï¼‰
        with httpx.Client(timeout=60.0) as client:
            resp = client.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {OPENAI_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "gpt-3.5-turbo",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„å¤§å­¸é¢è©¦å®˜ï¼Œåªå›å‚³ JSON é™£åˆ—ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.7,
                    "max_tokens": 1024
                }
            )
        
        print(f"ğŸ“¨ OpenAI å›æ‡‰: {resp.status_code}")
        
        if resp.status_code == 200:
            content = resp.json()["choices"][0]["message"]["content"]
            clean = content.replace("```json", "").replace("```", "").strip()
            questions = json.loads(clean)
            print(f"âœ… ç”Ÿæˆ {len(questions)} å€‹å€‹äººåŒ–å•é¡Œï¼")
            return {"success": True, "questions": questions}
        else:
            print(f"âš ï¸ API éŒ¯èª¤: {resp.status_code} - {resp.text}")
            return {"success": True, "questions": DEFAULT_QUESTIONS}
            
    except Exception as e:
        print(f"âŒ [Worker] éŒ¯èª¤: {e}")
        traceback.print_exc()
        return {"success": True, "questions": DEFAULT_QUESTIONS}


async def analyze_pdf_and_generate_questions(pdf_path: str, interview_type: str = "é€šç”¨å‹") -> dict:
    """
    éåŒæ­¥å…¥å£ - æŠŠå¯¦éš›å·¥ä½œäº¤çµ¦ ThreadPoolExecutor
    é€™æ¨£ä¸»ç¨‹å¼ä¸æœƒè¢«é˜»å¡ï¼Œä¹Ÿä¸æœƒå› ç‚ºä¸€å€‹ä»»å‹™å¤±æ•—è€Œå´©æ½°
    """
    loop = asyncio.get_event_loop()
    
    # â˜…â˜…â˜… åœ¨ç¨ç«‹ç·šç¨‹ä¸­åŸ·è¡ŒåŒæ­¥ä»»å‹™ â˜…â˜…â˜…
    result = await loop.run_in_executor(
        executor, 
        _process_pdf_and_call_openai_sync, 
        pdf_path, 
        interview_type
    )
    
    return result
