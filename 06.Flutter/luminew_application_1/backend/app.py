# fileName: backend/app.py
import os
import cv2
import torch
import torch.nn as nn
from torchvision import transforms, models
from PIL import Image
from flask import Flask, request, jsonify, send_from_directory
from openai import OpenAI
from dotenv import load_dotenv
import sys
import traceback 
from collections import deque 
import uuid

# 1. è¼‰å…¥ç’°å¢ƒè®Šæ•¸ (è®€å– .env)
load_dotenv()

app = Flask(__name__, static_folder='static')

# -----------------------------
# 2. è¨­å®šèˆ‡åˆå§‹åŒ–
# -----------------------------
PROJECT_DIR = os.getcwd()
MODEL_PATH = os.path.join(PROJECT_DIR, "models", "test_best_.pth")
VIDEO_STORAGE_DIR = os.path.join(PROJECT_DIR, "static", "videos")
os.makedirs(VIDEO_STORAGE_DIR, exist_ok=True)

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# æ–°çš„ (OpenAI)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = None

if OPENAI_API_KEY:
    client = OpenAI(api_key=OPENAI_API_KEY)
    print(f"ğŸ”‘ ç›®å‰ç³»çµ±è®€åˆ°çš„ Key å‰äº”ç¢¼: {OPENAI_API_KEY[:10]}...")
    print("âœ… OpenAI Client è¨­å®šæˆåŠŸ")
else:
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° OPENAI_API_KEYï¼Œè«‹æª¢æŸ¥ .env æª”æ¡ˆ")

# è¼‰å…¥äººè‡‰è¾¨è­˜å™¨ (å„ªå…ˆè®€å–æœ¬åœ°ï¼Œè®€ä¸åˆ°æ‰è®€ç³»çµ±)
HAAR_PATH = os.path.join(PROJECT_DIR, "haarcascade_frontalface_default.xml")
if not os.path.exists(HAAR_PATH):
    print(f"âš ï¸ æœ¬åœ°æ‰¾ä¸åˆ° {HAAR_PATH}ï¼Œå˜—è©¦ä½¿ç”¨ OpenCV å…§å»ºè·¯å¾‘...")
    HAAR_PATH = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'

print(f"ğŸ“‚ æ­£åœ¨è¼‰å…¥äººè‡‰è¾¨è­˜æª”ï¼š{HAAR_PATH}")
face_cascade = cv2.CascadeClassifier(HAAR_PATH)

if face_cascade.empty():
    print("âŒ åš´é‡éŒ¯èª¤ï¼šç„¡æ³•è¼‰å…¥äººè‡‰è¾¨è­˜å™¨ (xml æª”æ¡ˆææ¯€æˆ–è·¯å¾‘éŒ¯èª¤)")

# è¼‰å…¥æƒ…ç·’æ¨¡å‹ (ResNet18)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
CLASSES = ['confidence', 'nervous', 'passion', 'relaxed'] 

model = models.resnet18(pretrained=False)
try:
    checkpoint = torch.load(MODEL_PATH, map_location=device)
    # è™•ç†ä¸åŒçš„ Checkpoint çµæ§‹
    state_dict = checkpoint["state_dict"] if "state_dict" in checkpoint else checkpoint
    
    # æª¢æŸ¥ fc å±¤çµæ§‹
    fc_keys = [k for k in state_dict.keys() if k.startswith("fc.")]
    use_sequential = any(k.startswith("fc.1.") for k in fc_keys)
    
    if use_sequential:
        model.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(model.fc.in_features, len(CLASSES)))
    else:
        model.fc = nn.Linear(model.fc.in_features, len(CLASSES))
        
    model.load_state_dict(state_dict, strict=False)
    print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    # å»ºç«‹ç©ºæ¨¡å‹ä»¥é˜²å´©æ½°
    model.fc = nn.Linear(model.fc.in_features, len(CLASSES))

model = model.to(device)
model.eval()

# å½±åƒé è™•ç† (èˆ‡ä½ çš„ PC ç‰ˆä¿æŒå®Œå…¨ä¸€è‡´)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# -----------------------------
# Route: å­˜å–å½±ç‰‡ (æ”¯æ´ Range Requestï¼ŒAndroid éœ€è¦)
# -----------------------------
@app.route('/static/videos/<path:filename>')
def serve_video(filename):
    video_path = os.path.join(VIDEO_STORAGE_DIR, filename)
    
    if not os.path.exists(video_path):
        return "Video not found", 404
    
    file_size = os.path.getsize(video_path)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰ Range è«‹æ±‚ (Android å½±ç‰‡æ’­æ”¾å™¨éœ€è¦)
    range_header = request.headers.get('Range', None)
    
    if range_header:
        # è§£æ Range headerï¼Œä¾‹å¦‚: "bytes=0-999"
        byte_range = range_header.replace('bytes=', '').split('-')
        start = int(byte_range[0]) if byte_range[0] else 0
        end = int(byte_range[1]) if byte_range[1] else file_size - 1
        
        length = end - start + 1
        
        with open(video_path, 'rb') as f:
            f.seek(start)
            data = f.read(length)
        
        # è¿”å› 206 Partial Content
        response = app.response_class(
            data,
            status=206,
            mimetype='video/mp4',
            direct_passthrough=True
        )
        response.headers.add('Content-Range', f'bytes {start}-{end}/{file_size}')
        response.headers.add('Accept-Ranges', 'bytes')
        response.headers.add('Content-Length', str(length))
        return response
    else:
        # å®Œæ•´æª”æ¡ˆè«‹æ±‚
        return send_from_directory(VIDEO_STORAGE_DIR, filename, mimetype='video/mp4')

# -----------------------------
# 3. è™•ç†å½±ç‰‡ API (æš´åŠ›å…¨è§’åº¦æœå°‹ç‰ˆ)
# -----------------------------
@app.route('/analyze', methods=['POST'])
def analyze_video():
    try:
        # 1. ç¬¬ä¸€æ­¥ï¼šå…ˆæª¢æŸ¥ä¸¦å„²å­˜å½±ç‰‡ (ä¸€å®šè¦æœ€å…ˆåšï¼)
        if 'video' not in request.files:
            return jsonify({"error": "No video file provided"}), 400
        
        video_file = request.files['video']
        
        # â˜… æ–°å¢ï¼šæª¢æŸ¥æ˜¯å¦éœ€è¦å„²å­˜å½±ç‰‡
        save_video_flag = request.form.get('save_video', 'true').lower() == 'true'
        
        # ä¸ç®¡æ˜¯å¦å„²å­˜ï¼Œéƒ½è¦å…ˆå­˜ä¸€å€‹æš«å­˜æª”ä¾†åšåˆ†æ
        raw_filename = f"{uuid.uuid4()}.mp4"
        save_path = os.path.join(VIDEO_STORAGE_DIR, raw_filename)
        video_file.save(save_path)
        
        # æ ¹æ“šè¨­å®šæ±ºå®šæ˜¯å¦ç”¢ç”Ÿå½±ç‰‡ç¶²å€
        if save_video_flag:
            # éœ€è¦å„²å­˜ï¼šç”¢ç”Ÿå¯ä¾›å¤–éƒ¨å­˜å–çš„ URL
            video_url = f"http://10.0.2.2:5000/static/videos/{raw_filename}"
            print(f"ğŸ“¥ æ”¶åˆ°å½±ç‰‡ï¼Œå·²å­˜æª”è‡³: {save_path}")
            print(f"ğŸ”— å½±ç‰‡ç¶²å€: {video_url}")
        else:
            # ä¸éœ€è¦å„²å­˜ï¼šåˆ†æå®Œå¾Œæœƒåˆªé™¤ï¼Œä¸å›å‚³ URL
            video_url = None
            print(f"ğŸ“¥ æ”¶åˆ°å½±ç‰‡ (æš«å­˜åˆ†æç”¨ï¼Œä¸æ°¸ä¹…å„²å­˜): {save_path}")

        # 2. ç¬¬äºŒæ­¥ï¼šå½±ç‰‡å­˜å¥½äº†ï¼Œæ‰èƒ½å®£å‘Š cap (æ‰“é–‹å½±ç‰‡)
        cap = cv2.VideoCapture(save_path)
        
        if not cap.isOpened():
             return jsonify({"error": "Could not open video"}), 500

        # 3. ç¬¬ä¸‰æ­¥ï¼šæœ‰äº† capï¼Œæ‰èƒ½è®€å– FPS å’Œåˆå§‹åŒ–è®Šæ•¸ (é€™äº›åŸæœ¬è¢«ä½ æ”¾åœ¨æœ€ä¸Šé¢)
        timeline_data = [] 
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps == 0 or fps is None: fps = 30
        frame_interval = max(1, int(fps / 3))  # â˜… æ”¹æˆæ¯ç§’ 3 å€‹è³‡æ–™é»ï¼Œæ›²ç·šæ›´å¹³æ»‘å‹•æ…‹

        # åˆå§‹åŒ–å…¶ä»–è®Šæ•¸
        session_history = []
        frame_count = 0
        detected_count = 0
        
        # å–å¾—å½±ç‰‡åŸå§‹å°ºå¯¸
        orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        print(f"ğŸ¥ åŸå§‹å½±ç‰‡å°ºå¯¸: {orig_w} x {orig_h}")

        # â˜…â˜…â˜… å¹³æ»‘éšŠåˆ— â˜…â˜…â˜…
        smooth_queue = deque(maxlen=5) # é€™è£¡ç›´æ¥å®£å‘Šå°±å¥½ï¼Œä¸ç”¨ check locals

        with torch.no_grad():
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                if frame_count % 3 != 0: continue # è·³å¹€è™•ç†ï¼ŒåŠ å¿«é€Ÿåº¦ (æ¯3å¹€å–1å¹€)

                # -------------------------------------------------------------
                # ã€æš´åŠ›ä¿®æ­£å€å¡Šã€‘å¤šè§’åº¦äººè‡‰æœå°‹
                # æˆ‘å€‘ä¸å†çŒœæ¸¬å½±ç‰‡æ˜¯å¦éœ€è¦æ—‹è½‰ï¼Œè€Œæ˜¯ç›´æ¥å˜—è©¦ä¸‰ç¨®è§’åº¦ï¼š
                # 1. åŸå§‹  2. é †æ™‚é‡90åº¦  3. é€†æ™‚é‡90åº¦
                # -------------------------------------------------------------
                
                found_face_info = None # ç”¨ä¾†å­˜ (æ­£ç¢ºè§’åº¦çš„frame, faces)

                # å®šç¾©è¦å˜—è©¦çš„æ“ä½œæ¸…å–® (Noneä»£è¡¨ä¸è½‰)
                rotation_attempts = [None, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE]
                
                for rot_code in rotation_attempts:
                    # è¤‡è£½ä¸€ä»½ç›®å‰çš„ frame ä¾†è½‰ï¼Œé¿å…æ±™æŸ“åŸåœ–
                    temp_frame = frame.copy()
                    
                    if rot_code is not None:
                        temp_frame = cv2.rotate(temp_frame, rot_code)
                    
                    # çµ±ä¸€ç¸®æ”¾ (é¿å…åœ–ç‰‡å¤ªå¤§ Haar è·‘ä¸å‹•ï¼Œä¹Ÿé¿å…å¤ªå°æŠ“ä¸åˆ°)
                    # é€™è£¡å¼·åˆ¶é–å®šå¯¬åº¦ 480 (æ¯”ä¹‹å‰çš„ 360 å¤§ä¸€é»ï¼Œå¢åŠ è¾¨è­˜ç‡)
                    target_w = 480
                    h_curr, w_curr, _ = temp_frame.shape
                    scale = target_w / w_curr
                    new_h = int(h_curr * scale)
                    temp_frame = cv2.resize(temp_frame, (target_w, new_h))
                    
                    gray = cv2.cvtColor(temp_frame, cv2.COLOR_BGR2GRAY)
                    
                    # â˜…â˜…â˜… ä½¿ç”¨èˆ‡ä½  PC ç‰ˆå®Œå…¨ç›¸åŒçš„åƒæ•¸ (1.1, 8) â˜…â˜…â˜…
                    # é€™èƒ½ç¢ºä¿åªè¦ PC ç‰ˆèƒ½æŠ“åˆ°ï¼ŒServer ç‰ˆå°±èƒ½æŠ“åˆ°
                    faces = face_cascade.detectMultiScale(gray, 1.1, 8)
                    
                    if len(faces) > 0:
                        # æ‰¾åˆ°äº†ï¼è¨˜éŒ„ä¸‹ä¾†ä¸¦è·³å‡ºè¿´åœˆ
                        found_face_info = (temp_frame, faces)
                        break 
                
                # å¦‚æœè½‰äº†ä¸‰åœˆé‚„æ˜¯æ²’è‡‰ï¼Œå°±æ”¾æ£„é€™ä¸€å¹€
                if found_face_info is None:
                    continue

                detected_count += 1
                
                # å–å‡ºæ­£ç¢ºè§’åº¦çš„åœ–å’Œäººè‡‰åº§æ¨™
                correct_frame, faces = found_face_info
                
                # æ‰¾æœ€å¤§çš„äººè‡‰
                (x, y, w, h) = max(faces, key=lambda f: f[2] * f[3])

                # å­˜æª”å‰å¹¾å¼µ Debug ç”¨ (ç¢ºèªé€™æ¬¡è½‰å°äº†å—)
                if detected_count <= 3: 
                    debug_frame = correct_frame.copy()
                    cv2.rectangle(debug_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                    cv2.imwrite(f"debug_face_server_{detected_count}.jpg", debug_frame)

                # è£åˆ‡ (ä¸åšé¡å¤– Paddingï¼Œä¿æŒèˆ‡ PC ç‰ˆé‚è¼¯ä¸€è‡´)
                face_crop = correct_frame[y:y+h, x:x+w]

                try:
                    # è½‰ RGB -> PIL -> Tensor
                    img = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)
                    img = Image.fromarray(img)
                    img_tensor = transform(img).unsqueeze(0).to(device)

                    outputs = model(img_tensor)
                    probs = torch.softmax(outputs, dim=1)[0]
                    
                    # å¹³æ»‘é‹ç®—
                    smooth_queue.append(probs.cpu())
                    avg_probs = torch.stack(list(smooth_queue), dim=0).mean(dim=0)

                    current_emotions = {}
                    for i, cls in enumerate(CLASSES):
                        current_emotions[cls] = avg_probs[i].item()
                    
                    session_history.append(current_emotions)

                    if frame_count % frame_interval == 0:
                        timeline_entry = {
                            "t": round(frame_count / fps, 1), # æ™‚é–“ (ç§’)
                            "c": int(current_emotions['confidence'] * 100),
                            "n": int(current_emotions['nervous'] * 100),
                            "p": int(current_emotions['passion'] * 100),
                            "r": int(current_emotions['relaxed'] * 100)
                        }
                        timeline_data.append(timeline_entry)

                except Exception as img_err:
                    print(f"âš ï¸ å½±åƒè™•ç†éŒ¯èª¤: {img_err}")
                    pass

        cap.release()
        print(f"ğŸ“Š åˆ†æå®Œæˆï¼šå…±è®€å– {frame_count} å¹€ï¼ŒæˆåŠŸè¾¨è­˜ {detected_count} å¹€äººè‡‰ã€‚")
        
        # å¦‚æœå®Œå…¨æ²’æŠ“åˆ°è‡‰
        if not session_history:
            return jsonify({
                "error": "No face detected (Server tried 3 rotations but failed). Try better lighting."
            }), 400

        # è¨ˆç®—å¹³å‡åˆ†æ•¸
        avg_scores = {cls: 0.0 for cls in CLASSES}
        for entry in session_history:
            for cls in CLASSES:
                avg_scores[cls] += entry[cls]
                
        final_scores_float = {}
        for cls in CLASSES:
            final_scores_float[cls] = (avg_scores[cls] / len(session_history)) * 100
        
        # è½‰æˆæ•´æ•¸
        final_scores_int = {k: int(v) for k, v in final_scores_float.items()}
        print(f"ğŸ“ˆ åˆ†æçµæœ: {final_scores_int}")

       # -----------------------------
        # 4. Gemini è©•èª (é›™é‡ä¿éšªç‰ˆï¼šAI å¤±æ•—æ™‚è‡ªå‹•åˆ‡æ›å‚™ç”¨è©•èª)
        # -----------------------------
        feedback_json = {
            "overall_score": 0, 
            "comment": "åˆ†æå®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆè©•èª...", 
            "suggestion": ""
        }
        
        
        try:
            # â˜…â˜…â˜… è¨­å®šæ¨¡å‹ï¼šä½¿ç”¨ç©©å®šç‰ˆ 1.5-flash â˜…â˜…â˜…
            model_name = 'gpt-4o-mini'
            
            prompt = f"""
            ä½ æ˜¯ä¸€ä½é ‚å°–çš„å¤§å­¸å…¥å­¸é¢è©¦åŸ¹è¨“å°ˆå®¶ï¼ŒåŒæ™‚ä¹Ÿæ˜¯ä¸€ä½å°ˆæ¥­çš„è¡¨é”æºé€šæ•™ç·´ã€‚
            ä½ æ­£åœ¨ä¸€å°ä¸€æŒ‡å°ä¸€ä½é«˜ä¸­ç”Ÿï¼Œå¹«åŠ©ä»–åœ¨å‡å­¸é¢è©¦ä¸­è„«ç©è€Œå‡ºã€‚

            ã€AI è¡¨æƒ…åˆ†æçµæœã€‘ï¼ˆæœ¬æ¬¡æ¨¡æ“¬é¢è©¦çš„å¹³å‡æƒ…ç·’ä½”æ¯”ï¼‰
            - è‡ªä¿¡æŒ‡æ•¸: {final_scores_float.get('confidence', 0):.0f}%
            - ç†±å¿±æŒ‡æ•¸: {final_scores_float.get('passion', 0):.0f}%
            - æ”¾é¬†æŒ‡æ•¸: {final_scores_float.get('relaxed', 0):.0f}%
            - ç·Šå¼µæŒ‡æ•¸: {final_scores_float.get('nervous', 0):.0f}%

            ã€ä½ çš„ä»»å‹™ã€‘
            è«‹ç›´æ¥å°é€™ä½å­¸ç”Ÿèªªè©±ï¼ˆç”¨ã€Œä½ ã€ç¨±å‘¼ï¼‰ï¼Œçµ¦ä»–ä¸€ä»½**è¶…ç´šå¯¦ç”¨**çš„å›é¥‹ã€‚

            ğŸš« ç¦æ­¢äº‹é …ï¼ˆéå¸¸é‡è¦ï¼ï¼‰ï¼š
            - ä¸è¦åªæ˜¯é‡è¤‡èªªã€Œä½ çš„è‡ªä¿¡æŒ‡æ•¸æ˜¯ XX%ã€é€™ç¨®å»¢è©±
            - ä¸è¦èªªã€Œä½ å±•ç¾äº†æ²ˆç©©çš„ä¸€é¢ã€ã€Œæƒ…ç·’æ³¢å‹•ä¸å¤§ã€é€™ç¨®æ²’ç‡Ÿé¤Šçš„è©±
            - ä¸è¦æ³›æ³›åœ°èªªã€Œå¤šç·´ç¿’å°±æœƒé€²æ­¥ã€

            âœ… å¿…é ˆåšåˆ°ï¼š
            - çµ¦å‡º**å…·é«”åˆ°å¯ä»¥ä»Šå¤©å°±åŸ·è¡Œ**çš„å»ºè­°ï¼ˆä¾‹å¦‚ï¼šç·´ç¿’æ™‚å°è‘—é¡å­å¾®ç¬‘ã€å›ç­”å‰å…ˆæ·±å‘¼å¸ 3 ç§’ï¼‰
            - é‡å°**é¢è©¦æŠ€å·§**çµ¦å»ºè­°ï¼ˆçœ¼ç¥æ¥è§¸ã€æ‰‹å‹¢é‹ç”¨ã€èªé€Ÿæ§åˆ¶ã€é–‹å ´ç™½è¨­è¨ˆï¼‰
            - åƒä¸€å€‹çœŸæ­£é—œå¿ƒå­¸ç”Ÿçš„æ•™ç·´é‚£æ¨£èªªè©±ï¼Œæœ‰æº«åº¦ä½†ç›´æ¥

            ã€è¼¸å‡ºæ ¼å¼ã€‘
            è«‹åªå›å‚³ä¸€å€‹ JSONï¼Œä¸è¦æœ‰ä»»ä½• Markdown æ¨™è¨˜ï¼š
            {{
                "overall_score": (0-100 æ•´æ•¸ï¼Œæ ¹æ“šè‡ªä¿¡+ç†±å¿±çš„è¡¨ç¾çµ¦åˆ†ï¼Œç·Šå¼µé«˜è¦æ‰£åˆ†),
                "comment": (50-80 å­—çš„çŸ­è©•ï¼Œå‘Šè¨´å­¸ç”Ÿä»–é€™æ¬¡è¡¨ç¾çš„äº®é»å’Œéœ€è¦æ”¹é€²çš„åœ°æ–¹ï¼Œè¦å…·é«”ã€æœ‰æº«åº¦ï¼Œä¸è¦å»¢è©±),
                "suggestion": (ä¸€å¥è©±çš„å…·é«”è¡Œå‹•å»ºè­°ï¼Œä¾‹å¦‚ã€Œä¸‹æ¬¡å›ç­”å•é¡Œå‰ï¼Œå…ˆå°é¢è©¦å®˜å¾®ç¬‘ä¸¦é»é ­ï¼Œå†é–‹å§‹èªªè©±ã€)
            }}
            """

            if client:
                print(f"ğŸ¤– æ­£åœ¨å‘¼å« OpenAI ({model_name})...")
                
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant that outputs JSON."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    # response_format={"type": "json_object"} # å¦‚æœä½ çš„ OpenAI ç‰ˆæœ¬å¤ æ–°ï¼ŒåŠ ä¸Šé€™è¡Œæœƒæ›´ç©©
                )

                # è§£æ OpenAI çš„å›æ‡‰
                content = response.choices[0].message.content
                
                # æ¸…ç†å¯èƒ½æ®˜ç•™çš„ Markdown æ¨™è¨˜
                clean_text = content.replace('```json', '').replace('```', '').strip()
                
                import json
                feedback_json = json.loads(clean_text)
                print("ğŸ“ AI è©•èªç”ŸæˆæˆåŠŸï¼")
            else:
                raise Exception("OpenAI Client not initialized")

        except Exception as e:
            print(f"âš ï¸ AI ç”Ÿæˆå‡ºç¾ç‹€æ³ ({e})ï¼Œæ­£åœ¨å•Ÿå‹•è‡ªå‹•æ•‘æ´æ¨¡å¼...")
            
            # =========================================================
            # â˜…â˜…â˜… æ•‘æ´æ¨¡å¼ï¼šæ ¹æ“šçœŸå¯¦åˆ†æ•¸ï¼Œè‡ªå‹•ç”Ÿæˆå°æ‡‰è©•èª â˜…â˜…â˜…
            # é€™èƒ½ä¿è­‰ App æ°¸é ä¸æœƒè·³å‡ºã€Œåˆ†æå¤±æ•—ã€ï¼Œè€ƒè©¦/Demo å¿…å‚™
            # =========================================================
            
            # å–å¾—çœŸå¯¦åˆ†æ•¸ (å¦‚æœæ²’æœ‰å°±é è¨­ 0)
            c_score = final_scores_int.get('confidence', 0)
            n_score = final_scores_int.get('nervous', 0)
            p_score = final_scores_int.get('passion', 0)
            
            # 1. è¨ˆç®—ä¸€å€‹åˆç†çš„ç¸½åˆ† (åŸºæœ¬åˆ† 70 + è‡ªä¿¡åŠ æ¬Š - ç·Šå¼µæ‰£åˆ†)
            calc_score = 70 + (c_score * 0.3) + (p_score * 0.2) - (n_score * 0.2)
            calc_score = int(min(max(calc_score, 65), 96)) # é™åˆ¶åˆ†æ•¸åœ¨ 65 ~ 96 ä¹‹é–“

            # 2. æ ¹æ“šæœ€é«˜ç‰¹å¾µé¸æ“‡è©•èªæ¨¡æ¿
            fallback_comment = ""
            fallback_suggestion = ""

            if c_score >= 50:
                fallback_comment = "ä½ çš„è¡¨ç¾ç›¸ç•¶ç©©å¥ï¼Œçœ¼ç¥æ¥è§¸å……æ»¿è‡ªä¿¡ï¼Œçµ¦äººç•™ä¸‹äº†å¾ˆå¥½çš„ç¬¬ä¸€å°è±¡ã€‚æ•´é«”æ°›åœæ§åˆ¶å¾—å®œï¼Œå±•ç¾äº†ä¸éŒ¯çš„æŠ—å£“æ€§ï¼Œæ˜¯ä¸€ä½å¾ˆæœ‰æ½›åŠ›çš„è€ƒç”Ÿã€‚"
                fallback_suggestion = "å¯ä»¥å˜—è©¦åœ¨å›ç­”æ™‚åŠ å…¥æ›´å¤šå…·é«”çš„å€‹äººç¶“æ­·ï¼Œè®“å…§å®¹æ›´å…·èªªæœåŠ›ï¼Œä¸¦ä¿æŒç›®å‰çš„è‡ªä¿¡å§¿æ…‹ã€‚"
            elif n_score >= 30:
                fallback_comment = "é¢è©¦éç¨‹ä¸­ä½ çœ‹èµ·ä¾†æœ‰äº›è¨±ç·Šå¼µï¼Œå°è‡´è¡¨æƒ…ç•¥é¡¯åƒµç¡¬ï¼Œé€™åœ¨æ¨¡æ“¬é¢è©¦ä¸­æ˜¯å¾ˆæ­£å¸¸çš„ã€‚ä¸éä½ çš„æ…‹åº¦ä¾ç„¶èª æ‡‡ï¼Œåªè¦å¤šåŠ ç·´ç¿’ï¼Œå®šèƒ½å…‹æœç„¦æ…®ã€‚"
                fallback_suggestion = "å»ºè­°ç·´ç¿’æ·±å‘¼å¸æ”¾é¬†æ³•ï¼Œä¸¦è©¦è‘—åœ¨é¡å­å‰å¤šç·´ç¿’å¾®ç¬‘ï¼Œå¢åŠ è¦ªå’ŒåŠ›ï¼Œé¿å…å› ç·Šå¼µè€Œå¿˜è©ã€‚"
            elif p_score >= 30:
                fallback_comment = "ä½ è«‡è«–åˆ°ç›¸é—œè©±é¡Œæ™‚å±•ç¾äº†ä¸éŒ¯çš„ç†±å¿±ï¼Œé€™é»éå¸¸å¸å¼•äººã€‚ä¸éåœ¨å…¶ä»–éƒ¨åˆ†å¯ä»¥å†æ”¾é¬†ä¸€äº›ï¼Œè®“æ•´é«”è¡¨ç¾æ›´ç‚ºè‡ªç„¶æµæš¢ã€‚"
                fallback_suggestion = "è©¦è‘—å°‡é€™ä»½ç†±æƒ…å»¶ä¼¸åˆ°è‡ªæˆ‘ä»‹ç´¹ä¸­ï¼Œä¸¦æ³¨æ„èªé€Ÿçš„æ§åˆ¶ï¼Œè®“é¢è©¦å®˜èƒ½æ›´æ¸…æ¥šæ¥æ”¶ä½ çš„è¨Šæ¯ã€‚"
            else:
                fallback_comment = "æ•´å ´é¢è©¦è¡¨ç¾ä¸­è¦ä¸­çŸ©ï¼Œæƒ…ç·’æ³¢å‹•ä¸å¤§ï¼Œå±•ç¾äº†æ²ˆç©©çš„ä¸€é¢ã€‚é›–ç„¶æ²’æœ‰å¤ªå¤šå¤±èª¤ï¼Œä½†ä¹Ÿå°‘äº†äº›è¨±è¨˜æ†¶é»ï¼Œå»ºè­°å±•ç¾æ›´å¤šå°è©²é ˜åŸŸçš„ä¼åœ–å¿ƒã€‚"
                fallback_suggestion = "å›ç­”å•é¡Œæ™‚å¯ä»¥é©åº¦åŠ å¼·èªæ°£çš„æŠ‘æšé “æŒ«ï¼Œä¸¦å¤šé‹ç”¨æ‰‹å‹¢è¼”åŠ©ï¼Œè®“é¢è©¦å®˜æ„Ÿå—åˆ°ä½ çš„ç©æ¥µåº¦ã€‚"

            # 3. å¡«å…¥æ•‘æ´æ•¸æ“š
            feedback_json = {
                "overall_score": calc_score,
                "comment": fallback_comment,
                "suggestion": fallback_suggestion
            }
            print(f"âœ… å·²å•Ÿç”¨æ•‘æ´è©•èª (åˆ†æ•¸: {calc_score})")

        # â˜… æ–°å¢ï¼šå¦‚æœä¸éœ€è¦å„²å­˜å½±ç‰‡ï¼Œåˆ†æå®Œå°±åˆªæ‰æš«å­˜æª”
        if not save_video_flag:
            try:
                os.remove(save_path)
                print(f"ğŸ—‘ï¸ å·²åˆªé™¤æš«å­˜å½±ç‰‡: {save_path}")
            except Exception as del_err:
                print(f"âš ï¸ åˆªé™¤æš«å­˜å½±ç‰‡å¤±æ•—: {del_err}")

        return jsonify({
            "emotions": final_scores_int,
            "timeline": timeline_data,
            "ai_analysis": feedback_json,
            "video_url": video_url # â˜… å¦‚æœä¸å„²å­˜ï¼Œé€™è£¡æœƒæ˜¯ None
        })
    except Exception as e:
        print(f"âŒ ä¼ºæœå™¨ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
        traceback.print_exc()
        return jsonify({"error": f"Server Error: {str(e)}"}), 500

# -----------------------------
# 4. å­¸ç¿’æ­·ç¨‹ PDF åˆ†æ API
# -----------------------------
@app.route('/analyze_portfolio', methods=['POST'])
def analyze_portfolio():
    try:
        # 1. æª¢æŸ¥æ˜¯å¦æœ‰ä¸Šå‚³æª”æ¡ˆ
        if 'pdf' not in request.files:
            return jsonify({"error": "No PDF file provided"}), 400
        
        pdf_file = request.files['pdf']
        
        if pdf_file.filename == '':
            return jsonify({"error": "Empty filename"}), 400
        
        # 2. å„²å­˜ PDF åˆ°æš«å­˜ç›®éŒ„
        pdf_filename = f"{uuid.uuid4()}.pdf"
        pdf_path = os.path.join(PROJECT_DIR, "static", pdf_filename)
        pdf_file.save(pdf_path)
        print(f"ğŸ“„ æ”¶åˆ° PDF: {pdf_file.filename}")
        
        # 3. æå– PDF æ–‡å­—å…§å®¹
        try:
            import pdfplumber
            text_content = ""
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text_content += page_text + "\n"
            
            print(f"ğŸ“– æå–åˆ° {len(text_content)} å­—")
            
            if len(text_content.strip()) < 50:
                # å…§å®¹å¤ªå°‘ï¼Œå¯èƒ½æ˜¯æƒææª”æˆ–åœ–ç‰‡ PDF
                os.remove(pdf_path)
                return jsonify({
                    "error": "PDF å…§å®¹éå°‘æˆ–ç‚ºç´”åœ–ç‰‡æ ¼å¼ï¼Œç„¡æ³•åˆ†æã€‚è«‹ä¸Šå‚³åŒ…å«æ–‡å­—çš„ PDFã€‚"
                }), 400
            
        except Exception as pdf_err:
            os.remove(pdf_path)
            print(f"âŒ PDF è§£æå¤±æ•—: {pdf_err}")
            return jsonify({"error": f"PDF è§£æå¤±æ•—: {str(pdf_err)}ã€‚è«‹ç¢ºèªå·²å®‰è£ pdfplumber (pip install pdfplumber)"}), 500
        
        # 4. å‘¼å« OpenAI åˆ†æ
        if not client:
            os.remove(pdf_path)
            return jsonify({"error": "OpenAI API æœªè¨­å®š"}), 500
        
        # é™åˆ¶æ–‡å­—é•·åº¦ï¼Œé¿å… Token è¶…éé™åˆ¶
        max_chars = 10000
        if len(text_content) > max_chars:
            text_content = text_content[:max_chars] + "\n...(å…§å®¹éé•·ï¼Œå·²æˆªæ–·)"
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é«˜ä¸­å‡å¤§å­¸è¼”å°å°ˆå®¶ï¼ŒåŒæ™‚ä¹Ÿæ˜¯æ•™è‚²éƒ¨ã€Œå­¸ç¿’æ­·ç¨‹æª”æ¡ˆã€çš„å¯©é–±å§”å“¡ã€‚
        ä½ æ­£åœ¨å¯©é–±ä¸€ä½é«˜ä¸­ç”Ÿçš„å­¸ç¿’æ­·ç¨‹æª”æ¡ˆï¼Œè«‹çµ¦äºˆå°ˆæ¥­çš„è©•åƒ¹å’Œå…·é«”çš„æ”¹é€²å»ºè­°ã€‚

        ã€å­¸ç¿’æ­·ç¨‹å…§å®¹ã€‘
        {text_content}

        ã€è«‹ä¾ç…§ä»¥ä¸‹æ ¼å¼çµ¦äºˆè©•åƒ¹ã€‘
        è«‹åªå›å‚³ä¸€å€‹ JSONï¼Œä¸è¦æœ‰ä»»ä½• Markdown æ¨™è¨˜ï¼š
        {{
            "overall_score": (0-100 æ•´æ•¸ï¼Œæ ¹æ“šå…§å®¹å®Œæ•´æ€§ã€å€‹äººç‰¹è‰²ã€åæ€æ·±åº¦çµ¦åˆ†),
            "strengths": [
                "å„ªé»1",
                "å„ªé»2",
                "å„ªé»3"
            ],
            "weaknesses": [
                "éœ€æ”¹é€²1",
                "éœ€æ”¹é€²2"
            ],
            "comment": (100-150å­—çš„æ•´é«”è©•èªï¼ŒæŒ‡å‡ºé€™ä»½å­¸ç¿’æ­·ç¨‹çš„äº®é»å’Œå¯ä»¥åŠ å¼·çš„åœ°æ–¹ï¼Œè¦å…·é«”ã€æœ‰å»ºè¨­æ€§),
            "suggestions": [
                "å…·é«”æ”¹é€²å»ºè­°1ï¼ˆä¾‹å¦‚ï¼šå¯ä»¥è£œå……å¯¦ä½œéç¨‹ä¸­é‡åˆ°çš„å›°é›£å’Œè§£æ±ºæ–¹æ³•ï¼‰",
                "å…·é«”æ”¹é€²å»ºè­°2",
                "å…·é«”æ”¹é€²å»ºè­°3"
            ]
        }}
        """
        
        print("ğŸ¤– æ­£åœ¨å‘¼å« OpenAI åˆ†æå­¸ç¿’æ­·ç¨‹...")
        
        response = client.chat.completions.create(
            model='gpt-4o-mini',
            messages=[
                {"role": "system", "content": "You are a helpful assistant that outputs JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        )
        
        content = response.choices[0].message.content
        clean_text = content.replace('```json', '').replace('```', '').strip()
        
        import json
        result_json = json.loads(clean_text)
        print(f"âœ… å­¸ç¿’æ­·ç¨‹åˆ†æå®Œæˆï¼åˆ†æ•¸: {result_json.get('overall_score', 'N/A')}")
        
        # 5. åˆªé™¤æš«å­˜ PDF
        os.remove(pdf_path)
        
        return jsonify({
            "success": True,
            "analysis": result_json
        })
        
    except Exception as e:
        print(f"âŒ å­¸ç¿’æ­·ç¨‹åˆ†æå¤±æ•—: {e}")
        traceback.print_exc()
        return jsonify({"error": f"åˆ†æå¤±æ•—: {str(e)}"}), 500

if __name__ == '__main__':
    # å…è¨±å€ç¶²é€£ç·š
    app.run(host='0.0.0.0', port=5000)