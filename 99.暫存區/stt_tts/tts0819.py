# import torch
# from TTS.utils import radam

# # å°‡ RAdam åŠ å…¥ safe globals
# torch.serialization.add_safe_globals([radam.RAdam])

# from TTS.api import TTS #conda tts_env_310

# # é¸ä¸€å€‹æ”¯æ´å¤šèªç³»èˆ‡å¤šèªªè©±è€…çš„æ¨¡å‹
# model_name = "tts_models/zh-CN/baker/tacotron2-DDC-GST"

# # è¼‰å…¥æ¨¡å‹
# tts = TTS(model_name)

# print("æ”¯æ´çš„èªè¨€ï¼š", tts.languages)
# print("æ”¯æ´çš„èªªè©±äººï¼š", tts.speakers)

# language = "en"         # å ±éŒ¯ç„¡ä¸­æ–‡

# # text = "ä½ å¥½ï¼Œæˆ‘æ˜¯AIèªéŸ³åˆæˆç³»çµ±ã€‚"
# text = "Hello, i' m AI voice robot. Nice to meet you."

# output_path = r"D:\Desktop\\-\\testtttt\\tts_stt\\output.wav"

# # åŸ·è¡Œ TTS ä¸¦è¼¸å‡ºæª”æ¡ˆ
# tts.tts_to_file(text=text, speaker=tts.speakers[0], language=language, file_path=output_path)

# print("èªéŸ³å·²å„²å­˜åˆ°", output_path)


import torch
from TTS.api import TTS

# Get device
device = "cuda" if torch.cuda.is_available() else "cpu"

# List available ğŸ¸TTS models
print(TTS().list_models())

# Init TTS
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

# Run TTS
# â— Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language
# Text to speech list of amplitude values as output
wav = tts.tts(text="Hello world!", speaker_wav="my/cloning/audio.wav", language="en")
# Text to speech to a file
tts.tts_to_file(text="Hello world!", speaker_wav="my/cloning/audio.wav", language="en", file_path="output.wav")

34: tts_models/zh-CN/baker/tacotron2-DDC-GST
50: tts_models/tw_akuapem/openbible/vits
51: tts_models/tw_asante/openbible/vits