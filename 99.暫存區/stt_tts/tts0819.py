# import torch
# from TTS.utils import radam

# # å°‡ RAdam åŠ å…¥ safe globals
# torch.serialization.add_safe_globals([radam.RAdam])

# from TTS.api import TTS #conda tts_env_310

# # é¸ä¸€å€‹æ”¯æ´å¤šèªç³»èˆ‡å¤šèªªè©±è€…çš„æ¨¡å‹
# model_name = "tts_models/zh-CN/baker/tacotron2-DDC-GST"

# # è¼‰å…¥æ¨¡å‹
# tts = TTS(model_name)

# print("æ”¯æ´çš„èªè¨€ï¼š", tts.languages)
# print("æ”¯æ´çš„èªªè©±äººï¼š", tts.speakers)

# language = "en"         # å ±éŒ¯ç„¡ä¸­æ–‡

# # text = "ä½ å¥½ï¼Œæˆ‘æ˜¯AIèªéŸ³åˆæˆç³»çµ±ã€‚"
# text = "Hello, i' m AI voice robot. Nice to meet you."

# output_path = r"D:\Desktop\\-\\testtttt\\tts_stt\\output.wav"

# # åŸ·è¡Œ TTS ä¸¦è¼¸å‡ºæª”æ¡ˆ
# tts.tts_to_file(text=text, speaker=tts.speakers[0], language=language, file_path=output_path)

# print("èªéŸ³å·²å„²å­˜åˆ°", output_path)

"""
1-28æ˜¯ä¹‹å‰çš„ç¨‹å¼ç¢¼
31-48è¡Œæ˜¯ç¯„ä¾‹ç¨‹å¼ç¢¼ é‚„æ²’ç´°çœ‹ æˆ–è¨±èƒ½è§£æ±ºä¹‹å‰çš„å ±éŒ¯
"""

import torch
from TTS.api import TTS

# Get device
device = "cuda" if torch.cuda.is_available() else "cpu"

# List available ğŸ¸TTS models
print(TTS().list_models())

# Init TTS
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

# Run TTS
# â— Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language
# Text to speech list of amplitude values as output
wav = tts.tts(text="Hello world!", speaker_wav="my/cloning/audio.wav", language="en")
# Text to speech to a file
tts.tts_to_file(text="Hello world!", speaker_wav="my/cloning/audio.wav", language="en", file_path="output.wav")

    #æˆ‘å€‘å¯èƒ½å¯ä»¥ç”¨çš„TTSæ¨¡çµ„ 
34: tts_models/zh-CN/baker/tacotron2-DDC-GST
50: tts_models/tw_akuapem/openbible/vits
51: tts_models/tw_asante/openbible/vits

    #é‚„æ²’çœ‹API
https://developer.yating.tw/zh-TW/doc/introduction-%E7%94%A2%E5%93%81%E8%88%87%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%B4%B9
https://studio.yating.tw/intro/zh-TW

    #æƒ³è©¦è©¦çš„æ¨¡çµ„
https://www.youtube.com/watch?v=0PuslZHJQes
https://pyttsx3.readthedocs.io/en/latest/engine.html


https://medium.com/@zzxiang/text-to-speech-in-6-lines-of-python-code-free-no-online-api-a428a163decd
# from espnet2.bin.tts_inference import Text2Speech
# import soundfile
# text2speech = Text2Speech.from_pretrained("kan-bayashi/ljspeech_vits")
# text = "Hello, this is a text-to-speech test. Does my speech sound good?"
# speech = text2speech(text)["wav"]
# soundfile.write("output.wav", speech.numpy(), text2speech.fs, "PCM_16")